{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart Pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pole is attached by an un-actuated joint to a cart, which moves along a frictionless track. The system is controlled by applying a force of +1 or -1 to the cart. The pendulum starts upright, and the goal is to prevent it from falling over. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enviroment url: https://gym.openai.com/envs/CartPole-v1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving requirements: 195 score over 100 episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Action space: Discrete with 2 values:\n",
    "\n",
    "0 - Cart goes to the left\n",
    "\n",
    "1 - Cart goes to the right\n",
    "\n",
    "- State space: Box with 4 values:\n",
    "\n",
    "Cart position\n",
    "\n",
    "Cart velocity\n",
    "\n",
    "Pole angle\n",
    "\n",
    "Pole velocity at tip\n",
    "\n",
    "- Reward: if enviroment didn't ended $\\Rightarrow R_t=1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy gradient method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():\n",
    "    def __init__(self, s_size=4, a_size=2):\n",
    "        self.w=1e-4*np.random.rand(s_size, a_size)\n",
    "        self.a_size=a_size\n",
    "    def prob(self, state):\n",
    "        x = np.dot(state, self.w)\n",
    "        return np.exp(x)/np.sum(np.exp(x))\n",
    "    \n",
    "    def act(self, state):\n",
    "        prob = self.prob(state)\n",
    "        action = np.argmax(prob)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 1000/1000 ... score : 500.0\n"
     ]
    }
   ],
   "source": [
    "policy = Policy(4, 2)\n",
    "best_w = policy.w\n",
    "best_R=-np.inf\n",
    "noise_scale=1e-2\n",
    "num_episodes=1000\n",
    "gamma=1.0\n",
    "i_episode=0\n",
    "scores=deque(maxlen=100)\n",
    "while True:\n",
    "    i_episode+=1\n",
    "    rewards=[]\n",
    "    state=env.reset()\n",
    "    while True:\n",
    "        action=policy.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        state=next_state\n",
    "        if done:\n",
    "            break\n",
    "    scores.append(np.sum(rewards))\n",
    "    discounts=[gamma**i for i in range(len(rewards)+1)]\n",
    "    R=np.sum([a*b for a,b in zip(rewards, discounts)])\n",
    "    if R>=best_R:\n",
    "        best_R=R\n",
    "        best_w=policy.w\n",
    "        noise_scale = max(1e-3, noise_scale/2)\n",
    "        policy.w += noise_scale*np.random.rand(*policy.w.shape)\n",
    "    else:\n",
    "        noise_scale = min(2, noise_scale*2)\n",
    "        policy.w = best_w + noise_scale*np.random.rand(*policy.w.shape)\n",
    "    clear_output(True)\n",
    "    print('Episode : {}/{} ... score : {}'.format(i_episode, num_episodes, np.mean(scores))) \n",
    "    if i_episode>=num_episodes:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork():\n",
    "    def __init__(self, state_size, hidden_size, action_size,learning_rate=0.01, name='QNetwork'):\n",
    "        \n",
    "        with tf.variable_scope(name): \n",
    "            self.inputs_ = tf.placeholder(dtype=tf.float32, shape=[None, state_size], name='inputs')\n",
    "            \n",
    "            self.actions_ = tf.placeholder(dtype=tf.int32, shape=[None], name='actions')\n",
    "            one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "            \n",
    "            self.targetQs_ = tf.placeholder(dtype=tf.float32, shape=[None], name='target') \n",
    "            \n",
    "            self.fc1 = tf.contrib.layers.fully_connected(self.inputs_, num_outputs=hidden_size)\n",
    "            self.fc2 = tf.contrib.layers.fully_connected(self.fc1, num_outputs=hidden_size)\n",
    "            \n",
    "            self.output = tf.contrib.layers.fully_connected(self.fc2, num_outputs=action_size, activation_fn=None)\n",
    "            \n",
    "            self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "            \n",
    "            self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "            \n",
    "            self.opt = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory():\n",
    "    def __init__(self, max_size=1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), size=batch_size, replace=False)\n",
    "        \n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bgmello/.local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/bgmello/.local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "QAgent = QNetwork(name='network', hidden_size=64, learning_rate=0.0001, action_size=2, state_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "memory = Memory(max_size=1000)\n",
    "\n",
    "for ii in range(20):\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "    if done:\n",
    "        \n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        env.reset()\n",
    "        \n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: 9.0 Training loss: 1.0730 Explore P: 0.9955\n",
      "Episode: 2 Total reward: 23.0 Training loss: 1.0362 Explore P: 0.9841\n",
      "Episode: 3 Total reward: 10.0 Training loss: 1.1003 Explore P: 0.9792\n",
      "Episode: 4 Total reward: 12.0 Training loss: 1.1057 Explore P: 0.9734\n",
      "Episode: 5 Total reward: 14.0 Training loss: 0.9941 Explore P: 0.9666\n",
      "Episode: 6 Total reward: 26.0 Training loss: 1.0458 Explore P: 0.9541\n",
      "Episode: 7 Total reward: 17.0 Training loss: 1.0956 Explore P: 0.9461\n",
      "Episode: 8 Total reward: 22.0 Training loss: 1.1050 Explore P: 0.9357\n",
      "Episode: 9 Total reward: 21.0 Training loss: 1.1844 Explore P: 0.9260\n",
      "Episode: 10 Total reward: 11.0 Training loss: 1.1234 Explore P: 0.9209\n",
      "Episode: 11 Total reward: 15.0 Training loss: 1.2404 Explore P: 0.9140\n",
      "Episode: 12 Total reward: 10.0 Training loss: 1.2378 Explore P: 0.9095\n",
      "Episode: 13 Total reward: 10.0 Training loss: 1.2666 Explore P: 0.9049\n",
      "Episode: 14 Total reward: 27.0 Training loss: 1.2470 Explore P: 0.8928\n",
      "Episode: 15 Total reward: 21.0 Training loss: 1.4309 Explore P: 0.8835\n",
      "Episode: 16 Total reward: 37.0 Training loss: 1.5936 Explore P: 0.8673\n",
      "Episode: 17 Total reward: 31.0 Training loss: 1.4698 Explore P: 0.8540\n",
      "Episode: 18 Total reward: 16.0 Training loss: 1.4447 Explore P: 0.8472\n",
      "Episode: 19 Total reward: 9.0 Training loss: 1.7800 Explore P: 0.8434\n",
      "Episode: 20 Total reward: 27.0 Training loss: 1.7036 Explore P: 0.8321\n",
      "Episode: 21 Total reward: 11.0 Training loss: 1.3871 Explore P: 0.8275\n",
      "Episode: 22 Total reward: 23.0 Training loss: 1.7389 Explore P: 0.8181\n",
      "Episode: 23 Total reward: 16.0 Training loss: 1.9459 Explore P: 0.8116\n",
      "Episode: 24 Total reward: 23.0 Training loss: 2.0469 Explore P: 0.8023\n",
      "Episode: 25 Total reward: 17.0 Training loss: 1.9356 Explore P: 0.7955\n",
      "Episode: 26 Total reward: 12.0 Training loss: 1.8499 Explore P: 0.7908\n",
      "Episode: 27 Total reward: 22.0 Training loss: 2.0595 Explore P: 0.7821\n",
      "Episode: 28 Total reward: 9.0 Training loss: 1.9216 Explore P: 0.7786\n",
      "Episode: 29 Total reward: 21.0 Training loss: 2.3289 Explore P: 0.7705\n",
      "Episode: 30 Total reward: 13.0 Training loss: 2.1499 Explore P: 0.7655\n",
      "Episode: 31 Total reward: 14.0 Training loss: 4.9427 Explore P: 0.7602\n",
      "Episode: 32 Total reward: 14.0 Training loss: 2.9019 Explore P: 0.7549\n",
      "Episode: 33 Total reward: 19.0 Training loss: 2.8644 Explore P: 0.7478\n",
      "Episode: 34 Total reward: 13.0 Training loss: 2.6093 Explore P: 0.7429\n",
      "Episode: 35 Total reward: 9.0 Training loss: 6.2057 Explore P: 0.7396\n",
      "Episode: 36 Total reward: 16.0 Training loss: 3.3708 Explore P: 0.7337\n",
      "Episode: 37 Total reward: 12.0 Training loss: 3.8127 Explore P: 0.7293\n",
      "Episode: 38 Total reward: 17.0 Training loss: 2.7558 Explore P: 0.7232\n",
      "Episode: 39 Total reward: 14.0 Training loss: 6.0351 Explore P: 0.7181\n",
      "Episode: 40 Total reward: 11.0 Training loss: 5.9762 Explore P: 0.7142\n",
      "Episode: 41 Total reward: 11.0 Training loss: 2.4899 Explore P: 0.7103\n",
      "Episode: 42 Total reward: 11.0 Training loss: 5.6314 Explore P: 0.7064\n",
      "Episode: 43 Total reward: 22.0 Training loss: 9.6247 Explore P: 0.6987\n",
      "Episode: 44 Total reward: 16.0 Training loss: 7.0792 Explore P: 0.6931\n",
      "Episode: 45 Total reward: 12.0 Training loss: 5.1689 Explore P: 0.6890\n",
      "Episode: 46 Total reward: 8.0 Training loss: 13.2982 Explore P: 0.6862\n",
      "Episode: 47 Total reward: 10.0 Training loss: 3.3991 Explore P: 0.6828\n",
      "Episode: 48 Total reward: 15.0 Training loss: 3.0604 Explore P: 0.6777\n",
      "Episode: 49 Total reward: 12.0 Training loss: 7.3582 Explore P: 0.6737\n",
      "Episode: 50 Total reward: 9.0 Training loss: 6.8964 Explore P: 0.6706\n",
      "Episode: 51 Total reward: 10.0 Training loss: 5.7560 Explore P: 0.6673\n",
      "Episode: 52 Total reward: 8.0 Training loss: 8.0665 Explore P: 0.6646\n",
      "Episode: 53 Total reward: 12.0 Training loss: 5.9959 Explore P: 0.6607\n",
      "Episode: 54 Total reward: 8.0 Training loss: 3.3612 Explore P: 0.6580\n",
      "Episode: 55 Total reward: 19.0 Training loss: 13.4125 Explore P: 0.6518\n",
      "Episode: 56 Total reward: 12.0 Training loss: 16.7333 Explore P: 0.6479\n",
      "Episode: 57 Total reward: 13.0 Training loss: 8.8641 Explore P: 0.6437\n",
      "Episode: 58 Total reward: 17.0 Training loss: 3.3106 Explore P: 0.6383\n",
      "Episode: 59 Total reward: 10.0 Training loss: 4.4552 Explore P: 0.6351\n",
      "Episode: 60 Total reward: 8.0 Training loss: 9.4876 Explore P: 0.6326\n",
      "Episode: 61 Total reward: 11.0 Training loss: 17.0534 Explore P: 0.6291\n",
      "Episode: 62 Total reward: 11.0 Training loss: 12.5832 Explore P: 0.6257\n",
      "Episode: 63 Total reward: 10.0 Training loss: 18.9249 Explore P: 0.6226\n",
      "Episode: 64 Total reward: 30.0 Training loss: 6.3998 Explore P: 0.6133\n",
      "Episode: 65 Total reward: 15.0 Training loss: 4.7165 Explore P: 0.6087\n",
      "Episode: 66 Total reward: 10.0 Training loss: 13.0323 Explore P: 0.6057\n",
      "Episode: 67 Total reward: 9.0 Training loss: 15.8797 Explore P: 0.6030\n",
      "Episode: 68 Total reward: 27.0 Training loss: 3.5921 Explore P: 0.5949\n",
      "Episode: 69 Total reward: 12.0 Training loss: 2.5899 Explore P: 0.5914\n",
      "Episode: 70 Total reward: 13.0 Training loss: 13.1815 Explore P: 0.5875\n",
      "Episode: 71 Total reward: 9.0 Training loss: 11.5289 Explore P: 0.5849\n",
      "Episode: 72 Total reward: 9.0 Training loss: 11.0189 Explore P: 0.5823\n",
      "Episode: 73 Total reward: 8.0 Training loss: 12.9731 Explore P: 0.5800\n",
      "Episode: 74 Total reward: 11.0 Training loss: 18.4956 Explore P: 0.5768\n",
      "Episode: 75 Total reward: 9.0 Training loss: 8.8913 Explore P: 0.5742\n",
      "Episode: 76 Total reward: 9.0 Training loss: 2.9015 Explore P: 0.5716\n",
      "Episode: 77 Total reward: 12.0 Training loss: 3.8084 Explore P: 0.5682\n",
      "Episode: 78 Total reward: 9.0 Training loss: 15.4316 Explore P: 0.5657\n",
      "Episode: 79 Total reward: 10.0 Training loss: 4.1335 Explore P: 0.5629\n",
      "Episode: 80 Total reward: 17.0 Training loss: 20.0605 Explore P: 0.5581\n",
      "Episode: 81 Total reward: 16.0 Training loss: 4.1702 Explore P: 0.5537\n",
      "Episode: 82 Total reward: 8.0 Training loss: 18.5945 Explore P: 0.5515\n",
      "Episode: 83 Total reward: 19.0 Training loss: 4.0908 Explore P: 0.5463\n",
      "Episode: 84 Total reward: 18.0 Training loss: 8.6031 Explore P: 0.5414\n",
      "Episode: 85 Total reward: 12.0 Training loss: 19.0791 Explore P: 0.5381\n",
      "Episode: 86 Total reward: 15.0 Training loss: 12.6459 Explore P: 0.5341\n",
      "Episode: 87 Total reward: 9.0 Training loss: 40.3555 Explore P: 0.5317\n",
      "Episode: 88 Total reward: 14.0 Training loss: 12.9137 Explore P: 0.5280\n",
      "Episode: 89 Total reward: 20.0 Training loss: 4.1106 Explore P: 0.5228\n",
      "Episode: 90 Total reward: 10.0 Training loss: 21.4849 Explore P: 0.5202\n",
      "Episode: 91 Total reward: 13.0 Training loss: 15.4210 Explore P: 0.5168\n",
      "Episode: 92 Total reward: 21.0 Training loss: 12.3292 Explore P: 0.5114\n",
      "Episode: 93 Total reward: 13.0 Training loss: 27.2050 Explore P: 0.5081\n",
      "Episode: 94 Total reward: 9.0 Training loss: 9.4662 Explore P: 0.5058\n",
      "Episode: 95 Total reward: 13.0 Training loss: 20.8799 Explore P: 0.5026\n",
      "Episode: 96 Total reward: 13.0 Training loss: 34.1445 Explore P: 0.4993\n",
      "Episode: 97 Total reward: 15.0 Training loss: 27.5641 Explore P: 0.4956\n",
      "Episode: 98 Total reward: 10.0 Training loss: 3.8386 Explore P: 0.4931\n",
      "Episode: 99 Total reward: 13.0 Training loss: 3.5581 Explore P: 0.4899\n",
      "Episode: 100 Total reward: 18.0 Training loss: 31.6548 Explore P: 0.4856\n",
      "Episode: 101 Total reward: 8.0 Training loss: 8.9781 Explore P: 0.4836\n",
      "Episode: 102 Total reward: 12.0 Training loss: 47.1371 Explore P: 0.4807\n",
      "Episode: 103 Total reward: 10.0 Training loss: 28.8304 Explore P: 0.4784\n",
      "Episode: 104 Total reward: 11.0 Training loss: 3.8431 Explore P: 0.4757\n",
      "Episode: 105 Total reward: 18.0 Training loss: 9.5772 Explore P: 0.4715\n",
      "Episode: 106 Total reward: 7.0 Training loss: 24.9117 Explore P: 0.4698\n",
      "Episode: 107 Total reward: 12.0 Training loss: 15.8715 Explore P: 0.4670\n",
      "Episode: 108 Total reward: 13.0 Training loss: 16.7776 Explore P: 0.4640\n",
      "Episode: 109 Total reward: 10.0 Training loss: 3.9259 Explore P: 0.4617\n",
      "Episode: 110 Total reward: 10.0 Training loss: 24.7745 Explore P: 0.4594\n",
      "Episode: 111 Total reward: 8.0 Training loss: 24.0395 Explore P: 0.4576\n",
      "Episode: 112 Total reward: 13.0 Training loss: 26.7850 Explore P: 0.4546\n",
      "Episode: 113 Total reward: 14.0 Training loss: 3.5252 Explore P: 0.4515\n",
      "Episode: 114 Total reward: 10.0 Training loss: 48.4157 Explore P: 0.4492\n",
      "Episode: 115 Total reward: 11.0 Training loss: 13.9027 Explore P: 0.4467\n",
      "Episode: 116 Total reward: 17.0 Training loss: 25.5885 Explore P: 0.4430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 117 Total reward: 13.0 Training loss: 3.7234 Explore P: 0.4401\n",
      "Episode: 118 Total reward: 24.0 Training loss: 26.2979 Explore P: 0.4349\n",
      "Episode: 119 Total reward: 14.0 Training loss: 10.8814 Explore P: 0.4318\n",
      "Episode: 120 Total reward: 10.0 Training loss: 28.0934 Explore P: 0.4297\n",
      "Episode: 121 Total reward: 11.0 Training loss: 3.6315 Explore P: 0.4273\n",
      "Episode: 122 Total reward: 10.0 Training loss: 26.6993 Explore P: 0.4252\n",
      "Episode: 123 Total reward: 13.0 Training loss: 23.3092 Explore P: 0.4225\n",
      "Episode: 124 Total reward: 19.0 Training loss: 22.2183 Explore P: 0.4185\n",
      "Episode: 125 Total reward: 9.0 Training loss: 3.0465 Explore P: 0.4166\n",
      "Episode: 126 Total reward: 8.0 Training loss: 18.1069 Explore P: 0.4150\n",
      "Episode: 127 Total reward: 9.0 Training loss: 9.8307 Explore P: 0.4131\n",
      "Episode: 128 Total reward: 11.0 Training loss: 9.7501 Explore P: 0.4108\n",
      "Episode: 129 Total reward: 15.0 Training loss: 2.8931 Explore P: 0.4078\n",
      "Episode: 130 Total reward: 12.0 Training loss: 16.5496 Explore P: 0.4053\n",
      "Episode: 131 Total reward: 14.0 Training loss: 11.5426 Explore P: 0.4025\n",
      "Episode: 132 Total reward: 14.0 Training loss: 3.3015 Explore P: 0.3997\n",
      "Episode: 133 Total reward: 8.0 Training loss: 23.0648 Explore P: 0.3981\n",
      "Episode: 134 Total reward: 9.0 Training loss: 34.7349 Explore P: 0.3963\n",
      "Episode: 135 Total reward: 9.0 Training loss: 42.5778 Explore P: 0.3946\n",
      "Episode: 136 Total reward: 10.0 Training loss: 44.0836 Explore P: 0.3926\n",
      "Episode: 137 Total reward: 9.0 Training loss: 8.4070 Explore P: 0.3908\n",
      "Episode: 138 Total reward: 9.0 Training loss: 17.2909 Explore P: 0.3891\n",
      "Episode: 139 Total reward: 10.0 Training loss: 28.5996 Explore P: 0.3872\n",
      "Episode: 140 Total reward: 13.0 Training loss: 20.4329 Explore P: 0.3847\n",
      "Episode: 141 Total reward: 17.0 Training loss: 9.2378 Explore P: 0.3814\n",
      "Episode: 142 Total reward: 10.0 Training loss: 13.7676 Explore P: 0.3795\n",
      "Episode: 143 Total reward: 15.0 Training loss: 2.8564 Explore P: 0.3767\n",
      "Episode: 144 Total reward: 8.0 Training loss: 19.7111 Explore P: 0.3752\n",
      "Episode: 145 Total reward: 12.0 Training loss: 13.7017 Explore P: 0.3729\n",
      "Episode: 146 Total reward: 15.0 Training loss: 23.6959 Explore P: 0.3702\n",
      "Episode: 147 Total reward: 19.0 Training loss: 47.0703 Explore P: 0.3667\n",
      "Episode: 148 Total reward: 14.0 Training loss: 2.5604 Explore P: 0.3641\n",
      "Episode: 149 Total reward: 9.0 Training loss: 16.4386 Explore P: 0.3625\n",
      "Episode: 150 Total reward: 9.0 Training loss: 47.2971 Explore P: 0.3609\n",
      "Episode: 151 Total reward: 13.0 Training loss: 23.2155 Explore P: 0.3585\n",
      "Episode: 152 Total reward: 17.0 Training loss: 2.3376 Explore P: 0.3555\n",
      "Episode: 153 Total reward: 21.0 Training loss: 13.9178 Explore P: 0.3518\n",
      "Episode: 154 Total reward: 15.0 Training loss: 44.0848 Explore P: 0.3492\n",
      "Episode: 155 Total reward: 8.0 Training loss: 33.2564 Explore P: 0.3478\n",
      "Episode: 156 Total reward: 10.0 Training loss: 9.3705 Explore P: 0.3461\n",
      "Episode: 157 Total reward: 11.0 Training loss: 21.0155 Explore P: 0.3442\n",
      "Episode: 158 Total reward: 8.0 Training loss: 29.2225 Explore P: 0.3428\n",
      "Episode: 159 Total reward: 16.0 Training loss: 2.1803 Explore P: 0.3401\n",
      "Episode: 160 Total reward: 8.0 Training loss: 17.2310 Explore P: 0.3387\n",
      "Episode: 161 Total reward: 9.0 Training loss: 11.4922 Explore P: 0.3372\n",
      "Episode: 162 Total reward: 9.0 Training loss: 10.1988 Explore P: 0.3357\n",
      "Episode: 163 Total reward: 11.0 Training loss: 9.6985 Explore P: 0.3339\n",
      "Episode: 164 Total reward: 12.0 Training loss: 11.6654 Explore P: 0.3319\n",
      "Episode: 165 Total reward: 9.0 Training loss: 1.4064 Explore P: 0.3304\n",
      "Episode: 166 Total reward: 11.0 Training loss: 15.4277 Explore P: 0.3286\n",
      "Episode: 167 Total reward: 20.0 Training loss: 29.2493 Explore P: 0.3253\n",
      "Episode: 168 Total reward: 12.0 Training loss: 22.5134 Explore P: 0.3234\n",
      "Episode: 169 Total reward: 13.0 Training loss: 1.4078 Explore P: 0.3213\n",
      "Episode: 170 Total reward: 13.0 Training loss: 23.5973 Explore P: 0.3192\n",
      "Episode: 171 Total reward: 9.0 Training loss: 10.3493 Explore P: 0.3178\n",
      "Episode: 172 Total reward: 13.0 Training loss: 7.9273 Explore P: 0.3157\n",
      "Episode: 173 Total reward: 8.0 Training loss: 7.4082 Explore P: 0.3145\n",
      "Episode: 174 Total reward: 10.0 Training loss: 23.2699 Explore P: 0.3129\n",
      "Episode: 175 Total reward: 19.0 Training loss: 19.4687 Explore P: 0.3100\n",
      "Episode: 176 Total reward: 8.0 Training loss: 10.5551 Explore P: 0.3087\n",
      "Episode: 177 Total reward: 10.0 Training loss: 6.1632 Explore P: 0.3072\n",
      "Episode: 178 Total reward: 8.0 Training loss: 12.2448 Explore P: 0.3060\n",
      "Episode: 179 Total reward: 9.0 Training loss: 16.0701 Explore P: 0.3046\n",
      "Episode: 180 Total reward: 9.0 Training loss: 5.3879 Explore P: 0.3033\n",
      "Episode: 181 Total reward: 14.0 Training loss: 20.3707 Explore P: 0.3011\n",
      "Episode: 182 Total reward: 9.0 Training loss: 4.6308 Explore P: 0.2998\n",
      "Episode: 183 Total reward: 18.0 Training loss: 5.9465 Explore P: 0.2971\n",
      "Episode: 184 Total reward: 12.0 Training loss: 5.2950 Explore P: 0.2953\n",
      "Episode: 185 Total reward: 8.0 Training loss: 14.2364 Explore P: 0.2942\n",
      "Episode: 186 Total reward: 13.0 Training loss: 5.4623 Explore P: 0.2923\n",
      "Episode: 187 Total reward: 15.0 Training loss: 4.7745 Explore P: 0.2901\n",
      "Episode: 188 Total reward: 12.0 Training loss: 8.8582 Explore P: 0.2884\n",
      "Episode: 189 Total reward: 8.0 Training loss: 13.9512 Explore P: 0.2872\n",
      "Episode: 190 Total reward: 17.0 Training loss: 4.6892 Explore P: 0.2848\n",
      "Episode: 191 Total reward: 10.0 Training loss: 11.5294 Explore P: 0.2834\n",
      "Episode: 192 Total reward: 10.0 Training loss: 7.5956 Explore P: 0.2820\n",
      "Episode: 193 Total reward: 16.0 Training loss: 4.5262 Explore P: 0.2797\n",
      "Episode: 194 Total reward: 8.0 Training loss: 10.7955 Explore P: 0.2786\n",
      "Episode: 195 Total reward: 12.0 Training loss: 4.6750 Explore P: 0.2770\n",
      "Episode: 196 Total reward: 10.0 Training loss: 0.7129 Explore P: 0.2756\n",
      "Episode: 197 Total reward: 9.0 Training loss: 3.9019 Explore P: 0.2744\n",
      "Episode: 198 Total reward: 15.0 Training loss: 4.1084 Explore P: 0.2723\n",
      "Episode: 199 Total reward: 13.0 Training loss: 7.8162 Explore P: 0.2706\n",
      "Episode: 200 Total reward: 16.0 Training loss: 3.9142 Explore P: 0.2684\n",
      "Episode: 201 Total reward: 11.0 Training loss: 8.6353 Explore P: 0.2669\n",
      "Episode: 202 Total reward: 9.0 Training loss: 3.4298 Explore P: 0.2657\n",
      "Episode: 203 Total reward: 10.0 Training loss: 6.2062 Explore P: 0.2644\n",
      "Episode: 204 Total reward: 16.0 Training loss: 5.2053 Explore P: 0.2623\n",
      "Episode: 205 Total reward: 14.0 Training loss: 8.6578 Explore P: 0.2605\n",
      "Episode: 206 Total reward: 12.0 Training loss: 3.4832 Explore P: 0.2589\n",
      "Episode: 207 Total reward: 11.0 Training loss: 0.4834 Explore P: 0.2575\n",
      "Episode: 208 Total reward: 13.0 Training loss: 0.6380 Explore P: 0.2559\n",
      "Episode: 209 Total reward: 15.0 Training loss: 0.5820 Explore P: 0.2540\n",
      "Episode: 210 Total reward: 11.0 Training loss: 2.8777 Explore P: 0.2526\n",
      "Episode: 211 Total reward: 9.0 Training loss: 5.7723 Explore P: 0.2514\n",
      "Episode: 212 Total reward: 11.0 Training loss: 3.1784 Explore P: 0.2501\n",
      "Episode: 213 Total reward: 13.0 Training loss: 2.1237 Explore P: 0.2485\n",
      "Episode: 214 Total reward: 12.0 Training loss: 0.6213 Explore P: 0.2470\n",
      "Episode: 215 Total reward: 11.0 Training loss: 4.5798 Explore P: 0.2456\n",
      "Episode: 216 Total reward: 12.0 Training loss: 6.1688 Explore P: 0.2442\n",
      "Episode: 217 Total reward: 15.0 Training loss: 2.5464 Explore P: 0.2424\n",
      "Episode: 218 Total reward: 10.0 Training loss: 2.4314 Explore P: 0.2411\n",
      "Episode: 219 Total reward: 11.0 Training loss: 2.5855 Explore P: 0.2398\n",
      "Episode: 220 Total reward: 17.0 Training loss: 2.4059 Explore P: 0.2378\n",
      "Episode: 221 Total reward: 13.0 Training loss: 4.4009 Explore P: 0.2363\n",
      "Episode: 222 Total reward: 13.0 Training loss: 3.5323 Explore P: 0.2348\n",
      "Episode: 223 Total reward: 14.0 Training loss: 4.7560 Explore P: 0.2331\n",
      "Episode: 224 Total reward: 12.0 Training loss: 4.6007 Explore P: 0.2317\n",
      "Episode: 225 Total reward: 17.0 Training loss: 4.3566 Explore P: 0.2298\n",
      "Episode: 226 Total reward: 13.0 Training loss: 3.0218 Explore P: 0.2283\n",
      "Episode: 227 Total reward: 16.0 Training loss: 2.1216 Explore P: 0.2265\n",
      "Episode: 228 Total reward: 11.0 Training loss: 2.5959 Explore P: 0.2252\n",
      "Episode: 229 Total reward: 15.0 Training loss: 1.9129 Explore P: 0.2236\n",
      "Episode: 230 Total reward: 12.0 Training loss: 1.9847 Explore P: 0.2222\n",
      "Episode: 231 Total reward: 16.0 Training loss: 1.9188 Explore P: 0.2205\n",
      "Episode: 232 Total reward: 10.0 Training loss: 13.4963 Explore P: 0.2194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 233 Total reward: 14.0 Training loss: 1.8899 Explore P: 0.2179\n",
      "Episode: 234 Total reward: 16.0 Training loss: 2.4324 Explore P: 0.2161\n",
      "Episode: 235 Total reward: 12.0 Training loss: 2.8403 Explore P: 0.2148\n",
      "Episode: 236 Total reward: 13.0 Training loss: 3.1737 Explore P: 0.2135\n",
      "Episode: 237 Total reward: 16.0 Training loss: 6.2838 Explore P: 0.2118\n",
      "Episode: 238 Total reward: 14.0 Training loss: 2.3720 Explore P: 0.2103\n",
      "Episode: 239 Total reward: 11.0 Training loss: 6.3108 Explore P: 0.2091\n",
      "Episode: 240 Total reward: 14.0 Training loss: 4.4746 Explore P: 0.2077\n",
      "Episode: 241 Total reward: 16.0 Training loss: 3.8690 Explore P: 0.2061\n",
      "Episode: 242 Total reward: 12.0 Training loss: 0.5674 Explore P: 0.2048\n",
      "Episode: 243 Total reward: 14.0 Training loss: 3.1013 Explore P: 0.2034\n",
      "Episode: 244 Total reward: 14.0 Training loss: 2.9629 Explore P: 0.2020\n",
      "Episode: 245 Total reward: 9.0 Training loss: 3.3901 Explore P: 0.2011\n",
      "Episode: 246 Total reward: 17.0 Training loss: 4.5495 Explore P: 0.1994\n",
      "Episode: 247 Total reward: 11.0 Training loss: 20.9827 Explore P: 0.1983\n",
      "Episode: 248 Total reward: 17.0 Training loss: 2.7386 Explore P: 0.1966\n",
      "Episode: 249 Total reward: 15.0 Training loss: 4.7899 Explore P: 0.1952\n",
      "Episode: 250 Total reward: 18.0 Training loss: 3.6918 Explore P: 0.1934\n",
      "Episode: 251 Total reward: 15.0 Training loss: 0.6665 Explore P: 0.1920\n",
      "Episode: 252 Total reward: 16.0 Training loss: 5.4902 Explore P: 0.1905\n",
      "Episode: 253 Total reward: 20.0 Training loss: 2.6322 Explore P: 0.1886\n",
      "Episode: 254 Total reward: 19.0 Training loss: 4.1228 Explore P: 0.1868\n",
      "Episode: 255 Total reward: 22.0 Training loss: 1.3726 Explore P: 0.1848\n",
      "Episode: 256 Total reward: 34.0 Training loss: 5.5809 Explore P: 0.1817\n",
      "Episode: 257 Total reward: 29.0 Training loss: 8.1630 Explore P: 0.1791\n",
      "Episode: 258 Total reward: 9.0 Training loss: 4.1171 Explore P: 0.1783\n",
      "Episode: 259 Total reward: 41.0 Training loss: 0.6537 Explore P: 0.1747\n",
      "Episode: 260 Total reward: 39.0 Training loss: 29.5247 Explore P: 0.1713\n",
      "Episode: 261 Total reward: 9.0 Training loss: 4.2406 Explore P: 0.1706\n",
      "Episode: 262 Total reward: 9.0 Training loss: 6.4711 Explore P: 0.1698\n",
      "Episode: 263 Total reward: 19.0 Training loss: 34.3839 Explore P: 0.1682\n",
      "Episode: 264 Total reward: 22.0 Training loss: 4.5416 Explore P: 0.1664\n",
      "Episode: 265 Total reward: 17.0 Training loss: 0.9356 Explore P: 0.1650\n",
      "Episode: 266 Total reward: 18.0 Training loss: 3.6048 Explore P: 0.1635\n",
      "Episode: 267 Total reward: 26.0 Training loss: 1.4209 Explore P: 0.1614\n",
      "Episode: 268 Total reward: 14.0 Training loss: 16.8947 Explore P: 0.1603\n",
      "Episode: 269 Total reward: 16.0 Training loss: 1.0021 Explore P: 0.1590\n",
      "Episode: 270 Total reward: 14.0 Training loss: 7.5012 Explore P: 0.1579\n",
      "Episode: 271 Total reward: 19.0 Training loss: 8.2161 Explore P: 0.1564\n",
      "Episode: 272 Total reward: 19.0 Training loss: 24.4804 Explore P: 0.1550\n",
      "Episode: 273 Total reward: 17.0 Training loss: 0.9729 Explore P: 0.1537\n",
      "Episode: 274 Total reward: 16.0 Training loss: 4.9637 Explore P: 0.1524\n",
      "Episode: 275 Total reward: 16.0 Training loss: 26.5316 Explore P: 0.1512\n",
      "Episode: 276 Total reward: 12.0 Training loss: 5.4329 Explore P: 0.1503\n",
      "Episode: 277 Total reward: 17.0 Training loss: 4.5850 Explore P: 0.1491\n",
      "Episode: 278 Total reward: 22.0 Training loss: 0.6834 Explore P: 0.1475\n",
      "Episode: 279 Total reward: 16.0 Training loss: 4.9868 Explore P: 0.1463\n",
      "Episode: 280 Total reward: 16.0 Training loss: 8.8926 Explore P: 0.1451\n",
      "Episode: 281 Total reward: 9.0 Training loss: 4.3319 Explore P: 0.1445\n",
      "Episode: 282 Total reward: 16.0 Training loss: 14.0224 Explore P: 0.1433\n",
      "Episode: 283 Total reward: 15.0 Training loss: 1.2394 Explore P: 0.1423\n",
      "Episode: 284 Total reward: 17.0 Training loss: 22.9911 Explore P: 0.1411\n",
      "Episode: 285 Total reward: 18.0 Training loss: 1.0298 Explore P: 0.1398\n",
      "Episode: 286 Total reward: 19.0 Training loss: 10.5570 Explore P: 0.1385\n",
      "Episode: 287 Total reward: 17.0 Training loss: 5.8457 Explore P: 0.1374\n",
      "Episode: 288 Total reward: 8.0 Training loss: 10.5538 Explore P: 0.1368\n",
      "Episode: 289 Total reward: 18.0 Training loss: 21.1594 Explore P: 0.1356\n",
      "Episode: 290 Total reward: 16.0 Training loss: 5.7256 Explore P: 0.1345\n",
      "Episode: 291 Total reward: 18.0 Training loss: 16.1296 Explore P: 0.1333\n",
      "Episode: 292 Total reward: 16.0 Training loss: 14.9256 Explore P: 0.1323\n",
      "Episode: 293 Total reward: 16.0 Training loss: 6.0269 Explore P: 0.1312\n",
      "Episode: 294 Total reward: 13.0 Training loss: 15.0026 Explore P: 0.1304\n",
      "Episode: 295 Total reward: 11.0 Training loss: 11.0835 Explore P: 0.1297\n",
      "Episode: 296 Total reward: 14.0 Training loss: 5.4100 Explore P: 0.1288\n",
      "Episode: 297 Total reward: 10.0 Training loss: 11.0254 Explore P: 0.1281\n",
      "Episode: 298 Total reward: 14.0 Training loss: 21.0535 Explore P: 0.1272\n",
      "Episode: 299 Total reward: 15.0 Training loss: 5.6353 Explore P: 0.1263\n",
      "Episode: 300 Total reward: 14.0 Training loss: 19.2315 Explore P: 0.1254\n",
      "Episode: 301 Total reward: 21.0 Training loss: 20.2391 Explore P: 0.1241\n",
      "Episode: 302 Total reward: 18.0 Training loss: 14.8414 Explore P: 0.1230\n",
      "Episode: 303 Total reward: 17.0 Training loss: 1.4649 Explore P: 0.1220\n",
      "Episode: 304 Total reward: 12.0 Training loss: 15.1079 Explore P: 0.1213\n",
      "Episode: 305 Total reward: 12.0 Training loss: 6.0238 Explore P: 0.1206\n",
      "Episode: 306 Total reward: 15.0 Training loss: 5.8847 Explore P: 0.1197\n",
      "Episode: 307 Total reward: 16.0 Training loss: 16.2661 Explore P: 0.1187\n",
      "Episode: 308 Total reward: 16.0 Training loss: 11.6816 Explore P: 0.1178\n",
      "Episode: 309 Total reward: 21.0 Training loss: 14.7320 Explore P: 0.1166\n",
      "Episode: 310 Total reward: 16.0 Training loss: 13.9590 Explore P: 0.1156\n",
      "Episode: 311 Total reward: 9.0 Training loss: 12.2852 Explore P: 0.1151\n",
      "Episode: 312 Total reward: 13.0 Training loss: 0.7789 Explore P: 0.1144\n",
      "Episode: 313 Total reward: 13.0 Training loss: 12.1395 Explore P: 0.1136\n",
      "Episode: 314 Total reward: 14.0 Training loss: 0.7212 Explore P: 0.1129\n",
      "Episode: 315 Total reward: 14.0 Training loss: 1.2489 Explore P: 0.1121\n",
      "Episode: 316 Total reward: 12.0 Training loss: 1.8331 Explore P: 0.1114\n",
      "Episode: 317 Total reward: 12.0 Training loss: 13.3203 Explore P: 0.1108\n",
      "Episode: 318 Total reward: 12.0 Training loss: 19.8259 Explore P: 0.1101\n",
      "Episode: 319 Total reward: 10.0 Training loss: 6.8438 Explore P: 0.1096\n",
      "Episode: 320 Total reward: 16.0 Training loss: 6.6837 Explore P: 0.1087\n",
      "Episode: 321 Total reward: 12.0 Training loss: 21.1787 Explore P: 0.1080\n",
      "Episode: 322 Total reward: 15.0 Training loss: 18.4664 Explore P: 0.1072\n",
      "Episode: 323 Total reward: 12.0 Training loss: 14.0050 Explore P: 0.1066\n",
      "Episode: 324 Total reward: 10.0 Training loss: 12.7825 Explore P: 0.1061\n",
      "Episode: 325 Total reward: 11.0 Training loss: 12.1883 Explore P: 0.1055\n",
      "Episode: 326 Total reward: 9.0 Training loss: 43.6041 Explore P: 0.1050\n",
      "Episode: 327 Total reward: 11.0 Training loss: 15.3646 Explore P: 0.1045\n",
      "Episode: 328 Total reward: 16.0 Training loss: 7.0024 Explore P: 0.1036\n",
      "Episode: 329 Total reward: 9.0 Training loss: 0.7142 Explore P: 0.1032\n",
      "Episode: 330 Total reward: 9.0 Training loss: 18.7224 Explore P: 0.1027\n",
      "Episode: 331 Total reward: 12.0 Training loss: 12.3782 Explore P: 0.1021\n",
      "Episode: 332 Total reward: 9.0 Training loss: 6.6060 Explore P: 0.1017\n",
      "Episode: 333 Total reward: 14.0 Training loss: 0.7270 Explore P: 0.1010\n",
      "Episode: 334 Total reward: 8.0 Training loss: 0.8962 Explore P: 0.1006\n",
      "Episode: 335 Total reward: 11.0 Training loss: 11.4930 Explore P: 0.1000\n",
      "Episode: 336 Total reward: 10.0 Training loss: 5.9339 Explore P: 0.0995\n",
      "Episode: 337 Total reward: 11.0 Training loss: 1.0331 Explore P: 0.0990\n",
      "Episode: 338 Total reward: 15.0 Training loss: 11.8226 Explore P: 0.0982\n",
      "Episode: 339 Total reward: 10.0 Training loss: 16.3282 Explore P: 0.0978\n",
      "Episode: 340 Total reward: 12.0 Training loss: 6.1676 Explore P: 0.0972\n",
      "Episode: 341 Total reward: 9.0 Training loss: 0.5706 Explore P: 0.0968\n",
      "Episode: 342 Total reward: 8.0 Training loss: 22.6266 Explore P: 0.0964\n",
      "Episode: 343 Total reward: 9.0 Training loss: 0.6594 Explore P: 0.0959\n",
      "Episode: 344 Total reward: 12.0 Training loss: 14.8452 Explore P: 0.0954\n",
      "Episode: 345 Total reward: 14.0 Training loss: 9.9821 Explore P: 0.0947\n",
      "Episode: 346 Total reward: 11.0 Training loss: 10.4974 Explore P: 0.0942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 347 Total reward: 10.0 Training loss: 5.1328 Explore P: 0.0937\n",
      "Episode: 348 Total reward: 13.0 Training loss: 14.7061 Explore P: 0.0931\n",
      "Episode: 349 Total reward: 11.0 Training loss: 5.1014 Explore P: 0.0926\n",
      "Episode: 350 Total reward: 12.0 Training loss: 9.9143 Explore P: 0.0921\n",
      "Episode: 351 Total reward: 10.0 Training loss: 9.6691 Explore P: 0.0916\n",
      "Episode: 352 Total reward: 12.0 Training loss: 1.0526 Explore P: 0.0911\n",
      "Episode: 353 Total reward: 8.0 Training loss: 8.3015 Explore P: 0.0907\n",
      "Episode: 354 Total reward: 8.0 Training loss: 9.0311 Explore P: 0.0904\n",
      "Episode: 355 Total reward: 17.0 Training loss: 9.7740 Explore P: 0.0896\n",
      "Episode: 356 Total reward: 13.0 Training loss: 7.0710 Explore P: 0.0890\n",
      "Episode: 357 Total reward: 12.0 Training loss: 3.6471 Explore P: 0.0885\n",
      "Episode: 358 Total reward: 8.0 Training loss: 4.4886 Explore P: 0.0882\n",
      "Episode: 359 Total reward: 10.0 Training loss: 7.5491 Explore P: 0.0877\n",
      "Episode: 360 Total reward: 9.0 Training loss: 4.4814 Explore P: 0.0873\n",
      "Episode: 361 Total reward: 13.0 Training loss: 0.5865 Explore P: 0.0868\n",
      "Episode: 362 Total reward: 11.0 Training loss: 3.5306 Explore P: 0.0863\n",
      "Episode: 363 Total reward: 10.0 Training loss: 0.5975 Explore P: 0.0859\n",
      "Episode: 364 Total reward: 16.0 Training loss: 3.5983 Explore P: 0.0852\n",
      "Episode: 365 Total reward: 15.0 Training loss: 4.5715 Explore P: 0.0846\n",
      "Episode: 366 Total reward: 12.0 Training loss: 6.3879 Explore P: 0.0841\n",
      "Episode: 367 Total reward: 12.0 Training loss: 0.7956 Explore P: 0.0836\n",
      "Episode: 368 Total reward: 11.0 Training loss: 1.1383 Explore P: 0.0831\n",
      "Episode: 369 Total reward: 14.0 Training loss: 6.2504 Explore P: 0.0826\n",
      "Episode: 370 Total reward: 15.0 Training loss: 2.9651 Explore P: 0.0819\n",
      "Episode: 371 Total reward: 11.0 Training loss: 5.0299 Explore P: 0.0815\n",
      "Episode: 372 Total reward: 16.0 Training loss: 0.5061 Explore P: 0.0809\n",
      "Episode: 373 Total reward: 18.0 Training loss: 0.5230 Explore P: 0.0801\n",
      "Episode: 374 Total reward: 22.0 Training loss: 4.9255 Explore P: 0.0793\n",
      "Episode: 375 Total reward: 20.0 Training loss: 5.5409 Explore P: 0.0785\n",
      "Episode: 376 Total reward: 14.0 Training loss: 3.1678 Explore P: 0.0780\n",
      "Episode: 377 Total reward: 21.0 Training loss: 2.6765 Explore P: 0.0772\n",
      "Episode: 378 Total reward: 19.0 Training loss: 0.6199 Explore P: 0.0764\n",
      "Episode: 379 Total reward: 20.0 Training loss: 0.5467 Explore P: 0.0757\n",
      "Episode: 380 Total reward: 17.0 Training loss: 0.4844 Explore P: 0.0751\n",
      "Episode: 381 Total reward: 21.0 Training loss: 3.6918 Explore P: 0.0743\n",
      "Episode: 382 Total reward: 24.0 Training loss: 2.7184 Explore P: 0.0734\n",
      "Episode: 383 Total reward: 22.0 Training loss: 6.7530 Explore P: 0.0726\n",
      "Episode: 384 Total reward: 28.0 Training loss: 5.8062 Explore P: 0.0716\n",
      "Episode: 385 Total reward: 20.0 Training loss: 4.5396 Explore P: 0.0709\n",
      "Episode: 386 Total reward: 24.0 Training loss: 2.3626 Explore P: 0.0701\n",
      "Episode: 387 Total reward: 18.0 Training loss: 0.9049 Explore P: 0.0695\n",
      "Episode: 388 Total reward: 18.0 Training loss: 2.5100 Explore P: 0.0688\n",
      "Episode: 389 Total reward: 21.0 Training loss: 3.5837 Explore P: 0.0681\n",
      "Episode: 390 Total reward: 23.0 Training loss: 6.1986 Explore P: 0.0674\n",
      "Episode: 391 Total reward: 35.0 Training loss: 6.7397 Explore P: 0.0662\n",
      "Episode: 392 Total reward: 98.0 Training loss: 0.8114 Explore P: 0.0631\n",
      "Episode: 393 Total reward: 51.0 Training loss: 1.8470 Explore P: 0.0615\n",
      "Episode: 394 Total reward: 96.0 Training loss: 8.4692 Explore P: 0.0587\n",
      "Episode: 395 Total reward: 15.0 Training loss: 1.1572 Explore P: 0.0583\n",
      "Episode: 396 Total reward: 15.0 Training loss: 7.2176 Explore P: 0.0578\n",
      "Episode: 397 Total reward: 8.0 Training loss: 1.1392 Explore P: 0.0576\n",
      "Episode: 398 Total reward: 10.0 Training loss: 11.1923 Explore P: 0.0573\n",
      "Episode: 399 Total reward: 10.0 Training loss: 19.4789 Explore P: 0.0571\n",
      "Episode: 400 Total reward: 9.0 Training loss: 1.3039 Explore P: 0.0568\n",
      "Episode: 401 Total reward: 9.0 Training loss: 34.3131 Explore P: 0.0565\n",
      "Episode: 402 Total reward: 9.0 Training loss: 26.4593 Explore P: 0.0563\n",
      "Episode: 403 Total reward: 9.0 Training loss: 8.7753 Explore P: 0.0561\n",
      "Episode: 404 Total reward: 8.0 Training loss: 27.5289 Explore P: 0.0558\n",
      "Episode: 405 Total reward: 11.0 Training loss: 1.1870 Explore P: 0.0555\n",
      "Episode: 406 Total reward: 8.0 Training loss: 18.7588 Explore P: 0.0553\n",
      "Episode: 407 Total reward: 7.0 Training loss: 1.9428 Explore P: 0.0551\n",
      "Episode: 408 Total reward: 10.0 Training loss: 14.9647 Explore P: 0.0549\n",
      "Episode: 409 Total reward: 8.0 Training loss: 9.6687 Explore P: 0.0546\n",
      "Episode: 410 Total reward: 10.0 Training loss: 27.0970 Explore P: 0.0544\n",
      "Episode: 411 Total reward: 10.0 Training loss: 10.2082 Explore P: 0.0541\n",
      "Episode: 412 Total reward: 11.0 Training loss: 11.0263 Explore P: 0.0538\n",
      "Episode: 413 Total reward: 8.0 Training loss: 0.7796 Explore P: 0.0536\n",
      "Episode: 414 Total reward: 12.0 Training loss: 5.6911 Explore P: 0.0533\n",
      "Episode: 415 Total reward: 9.0 Training loss: 5.4359 Explore P: 0.0531\n",
      "Episode: 416 Total reward: 7.0 Training loss: 0.7730 Explore P: 0.0529\n",
      "Episode: 417 Total reward: 8.0 Training loss: 6.0318 Explore P: 0.0527\n",
      "Episode: 418 Total reward: 9.0 Training loss: 19.2683 Explore P: 0.0524\n",
      "Episode: 419 Total reward: 8.0 Training loss: 5.3390 Explore P: 0.0522\n",
      "Episode: 420 Total reward: 9.0 Training loss: 1.1418 Explore P: 0.0520\n",
      "Episode: 421 Total reward: 10.0 Training loss: 1.2201 Explore P: 0.0517\n",
      "Episode: 422 Total reward: 12.0 Training loss: 6.5513 Explore P: 0.0514\n",
      "Episode: 423 Total reward: 8.0 Training loss: 21.2295 Explore P: 0.0512\n",
      "Episode: 424 Total reward: 11.0 Training loss: 30.5189 Explore P: 0.0510\n",
      "Episode: 425 Total reward: 9.0 Training loss: 1.0778 Explore P: 0.0507\n",
      "Episode: 426 Total reward: 11.0 Training loss: 17.5684 Explore P: 0.0505\n",
      "Episode: 427 Total reward: 10.0 Training loss: 17.3584 Explore P: 0.0502\n",
      "Episode: 428 Total reward: 10.0 Training loss: 6.0395 Explore P: 0.0500\n",
      "Episode: 429 Total reward: 20.0 Training loss: 0.8552 Explore P: 0.0495\n",
      "Episode: 430 Total reward: 10.0 Training loss: 0.9088 Explore P: 0.0492\n",
      "Episode: 431 Total reward: 23.0 Training loss: 14.4249 Explore P: 0.0487\n",
      "Episode: 432 Total reward: 10.0 Training loss: 38.9540 Explore P: 0.0485\n",
      "Episode: 433 Total reward: 24.0 Training loss: 0.5940 Explore P: 0.0479\n",
      "Episode: 434 Total reward: 10.0 Training loss: 1.3091 Explore P: 0.0477\n",
      "Episode: 435 Total reward: 12.0 Training loss: 12.0656 Explore P: 0.0474\n",
      "Episode: 436 Total reward: 12.0 Training loss: 1.0379 Explore P: 0.0471\n",
      "Episode: 437 Total reward: 11.0 Training loss: 1.0770 Explore P: 0.0468\n",
      "Episode: 438 Total reward: 10.0 Training loss: 1.1447 Explore P: 0.0466\n",
      "Episode: 439 Total reward: 10.0 Training loss: 17.2468 Explore P: 0.0464\n",
      "Episode: 440 Total reward: 8.0 Training loss: 12.4217 Explore P: 0.0462\n",
      "Episode: 441 Total reward: 12.0 Training loss: 17.1119 Explore P: 0.0459\n",
      "Episode: 442 Total reward: 10.0 Training loss: 11.2145 Explore P: 0.0457\n",
      "Episode: 443 Total reward: 9.0 Training loss: 9.8016 Explore P: 0.0455\n",
      "Episode: 444 Total reward: 7.0 Training loss: 1.2656 Explore P: 0.0454\n",
      "Episode: 445 Total reward: 7.0 Training loss: 17.1438 Explore P: 0.0452\n",
      "Episode: 446 Total reward: 12.0 Training loss: 0.9457 Explore P: 0.0449\n",
      "Episode: 447 Total reward: 9.0 Training loss: 25.6003 Explore P: 0.0447\n",
      "Episode: 448 Total reward: 10.0 Training loss: 11.1409 Explore P: 0.0445\n",
      "Episode: 449 Total reward: 8.0 Training loss: 11.7748 Explore P: 0.0443\n",
      "Episode: 450 Total reward: 8.0 Training loss: 12.0038 Explore P: 0.0442\n",
      "Episode: 451 Total reward: 13.0 Training loss: 24.3826 Explore P: 0.0439\n",
      "Episode: 452 Total reward: 10.0 Training loss: 11.5488 Explore P: 0.0437\n",
      "Episode: 453 Total reward: 11.0 Training loss: 1.1531 Explore P: 0.0434\n",
      "Episode: 454 Total reward: 11.0 Training loss: 17.1520 Explore P: 0.0432\n",
      "Episode: 455 Total reward: 10.0 Training loss: 10.9822 Explore P: 0.0430\n",
      "Episode: 456 Total reward: 11.0 Training loss: 0.9724 Explore P: 0.0428\n",
      "Episode: 457 Total reward: 10.0 Training loss: 22.3781 Explore P: 0.0426\n",
      "Episode: 458 Total reward: 8.0 Training loss: 23.8651 Explore P: 0.0424\n",
      "Episode: 459 Total reward: 12.0 Training loss: 9.8832 Explore P: 0.0422\n",
      "Episode: 460 Total reward: 11.0 Training loss: 11.9999 Explore P: 0.0419\n",
      "Episode: 461 Total reward: 10.0 Training loss: 22.5926 Explore P: 0.0417\n",
      "Episode: 462 Total reward: 12.0 Training loss: 21.0149 Explore P: 0.0415\n",
      "Episode: 463 Total reward: 12.0 Training loss: 10.8304 Explore P: 0.0412\n",
      "Episode: 464 Total reward: 11.0 Training loss: 13.4263 Explore P: 0.0410\n",
      "Episode: 465 Total reward: 11.0 Training loss: 9.4191 Explore P: 0.0408\n",
      "Episode: 466 Total reward: 10.0 Training loss: 7.0964 Explore P: 0.0406\n",
      "Episode: 467 Total reward: 8.0 Training loss: 18.3332 Explore P: 0.0404\n",
      "Episode: 468 Total reward: 12.0 Training loss: 1.3308 Explore P: 0.0402\n",
      "Episode: 469 Total reward: 15.0 Training loss: 20.0244 Explore P: 0.0399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 470 Total reward: 11.0 Training loss: 0.9594 Explore P: 0.0397\n",
      "Episode: 471 Total reward: 9.0 Training loss: 14.6869 Explore P: 0.0395\n",
      "Episode: 472 Total reward: 11.0 Training loss: 1.3689 Explore P: 0.0393\n",
      "Episode: 473 Total reward: 11.0 Training loss: 22.6821 Explore P: 0.0391\n",
      "Episode: 474 Total reward: 15.0 Training loss: 23.1423 Explore P: 0.0388\n",
      "Episode: 475 Total reward: 9.0 Training loss: 6.2993 Explore P: 0.0386\n",
      "Episode: 476 Total reward: 12.0 Training loss: 5.9962 Explore P: 0.0384\n",
      "Episode: 477 Total reward: 10.0 Training loss: 16.7061 Explore P: 0.0382\n",
      "Episode: 478 Total reward: 12.0 Training loss: 5.3327 Explore P: 0.0380\n",
      "Episode: 479 Total reward: 11.0 Training loss: 9.6661 Explore P: 0.0378\n",
      "Episode: 480 Total reward: 9.0 Training loss: 0.8523 Explore P: 0.0376\n",
      "Episode: 481 Total reward: 9.0 Training loss: 5.1161 Explore P: 0.0375\n",
      "Episode: 482 Total reward: 11.0 Training loss: 8.8843 Explore P: 0.0373\n",
      "Episode: 483 Total reward: 7.0 Training loss: 1.3012 Explore P: 0.0372\n",
      "Episode: 484 Total reward: 12.0 Training loss: 8.5059 Explore P: 0.0369\n",
      "Episode: 485 Total reward: 8.0 Training loss: 4.5520 Explore P: 0.0368\n",
      "Episode: 486 Total reward: 9.0 Training loss: 9.6933 Explore P: 0.0366\n",
      "Episode: 487 Total reward: 9.0 Training loss: 0.9996 Explore P: 0.0365\n",
      "Episode: 488 Total reward: 8.0 Training loss: 3.7382 Explore P: 0.0363\n",
      "Episode: 489 Total reward: 9.0 Training loss: 15.6385 Explore P: 0.0362\n",
      "Episode: 490 Total reward: 10.0 Training loss: 3.5843 Explore P: 0.0360\n",
      "Episode: 491 Total reward: 8.0 Training loss: 6.5109 Explore P: 0.0359\n",
      "Episode: 492 Total reward: 10.0 Training loss: 11.0312 Explore P: 0.0357\n",
      "Episode: 493 Total reward: 14.0 Training loss: 2.5564 Explore P: 0.0354\n",
      "Episode: 494 Total reward: 10.0 Training loss: 6.1842 Explore P: 0.0353\n",
      "Episode: 495 Total reward: 10.0 Training loss: 19.6464 Explore P: 0.0351\n",
      "Episode: 496 Total reward: 12.0 Training loss: 14.9670 Explore P: 0.0349\n",
      "Episode: 497 Total reward: 10.0 Training loss: 19.1842 Explore P: 0.0347\n",
      "Episode: 498 Total reward: 11.0 Training loss: 12.5939 Explore P: 0.0345\n",
      "Episode: 499 Total reward: 12.0 Training loss: 4.6440 Explore P: 0.0343\n",
      "Episode: 500 Total reward: 8.0 Training loss: 0.7994 Explore P: 0.0342\n",
      "Episode: 501 Total reward: 9.0 Training loss: 1.4649 Explore P: 0.0341\n",
      "Episode: 502 Total reward: 11.0 Training loss: 27.3049 Explore P: 0.0339\n",
      "Episode: 503 Total reward: 12.0 Training loss: 9.0602 Explore P: 0.0337\n",
      "Episode: 504 Total reward: 12.0 Training loss: 10.3925 Explore P: 0.0335\n",
      "Episode: 505 Total reward: 15.0 Training loss: 0.5246 Explore P: 0.0332\n",
      "Episode: 506 Total reward: 9.0 Training loss: 2.5912 Explore P: 0.0331\n",
      "Episode: 507 Total reward: 12.0 Training loss: 7.3703 Explore P: 0.0329\n",
      "Episode: 508 Total reward: 16.0 Training loss: 7.9668 Explore P: 0.0327\n",
      "Episode: 509 Total reward: 18.0 Training loss: 8.1604 Explore P: 0.0324\n",
      "Episode: 510 Total reward: 15.0 Training loss: 2.7228 Explore P: 0.0321\n",
      "Episode: 511 Total reward: 13.0 Training loss: 10.6833 Explore P: 0.0319\n",
      "Episode: 512 Total reward: 17.0 Training loss: 3.1541 Explore P: 0.0317\n",
      "Episode: 513 Total reward: 35.0 Training loss: 0.5051 Explore P: 0.0311\n",
      "Episode: 514 Total reward: 42.0 Training loss: 1.3975 Explore P: 0.0305\n",
      "Episode: 515 Total reward: 37.0 Training loss: 0.3066 Explore P: 0.0300\n",
      "Episode: 516 Total reward: 32.0 Training loss: 0.6794 Explore P: 0.0295\n",
      "Episode: 517 Total reward: 11.0 Training loss: 0.4927 Explore P: 0.0294\n",
      "Episode: 518 Total reward: 14.0 Training loss: 2.7838 Explore P: 0.0292\n",
      "Episode: 519 Total reward: 56.0 Training loss: 0.8168 Explore P: 0.0284\n",
      "Episode: 520 Total reward: 12.0 Training loss: 1.7539 Explore P: 0.0282\n",
      "Episode: 521 Total reward: 8.0 Training loss: 0.5461 Explore P: 0.0281\n",
      "Episode: 522 Total reward: 52.0 Training loss: 1.1909 Explore P: 0.0274\n",
      "Episode: 523 Total reward: 10.0 Training loss: 9.6528 Explore P: 0.0273\n",
      "Episode: 524 Total reward: 10.0 Training loss: 1.2305 Explore P: 0.0271\n",
      "Episode: 525 Total reward: 8.0 Training loss: 0.9263 Explore P: 0.0270\n",
      "Episode: 526 Total reward: 11.0 Training loss: 1.1567 Explore P: 0.0269\n",
      "Episode: 527 Total reward: 11.0 Training loss: 0.3642 Explore P: 0.0268\n",
      "Episode: 528 Total reward: 8.0 Training loss: 7.9969 Explore P: 0.0267\n",
      "Episode: 529 Total reward: 12.0 Training loss: 10.3833 Explore P: 0.0265\n",
      "Episode: 530 Total reward: 8.0 Training loss: 10.7266 Explore P: 0.0264\n",
      "Episode: 531 Total reward: 8.0 Training loss: 1.0135 Explore P: 0.0263\n",
      "Episode: 532 Total reward: 9.0 Training loss: 10.6776 Explore P: 0.0262\n",
      "Episode: 533 Total reward: 9.0 Training loss: 0.9803 Explore P: 0.0261\n",
      "Episode: 534 Total reward: 7.0 Training loss: 10.5496 Explore P: 0.0260\n",
      "Episode: 535 Total reward: 9.0 Training loss: 10.1358 Explore P: 0.0259\n",
      "Episode: 536 Total reward: 8.0 Training loss: 3.4852 Explore P: 0.0258\n",
      "Episode: 537 Total reward: 11.0 Training loss: 3.8972 Explore P: 0.0256\n",
      "Episode: 538 Total reward: 10.0 Training loss: 8.5466 Explore P: 0.0255\n",
      "Episode: 539 Total reward: 10.0 Training loss: 9.7852 Explore P: 0.0254\n",
      "Episode: 540 Total reward: 10.0 Training loss: 10.1865 Explore P: 0.0253\n",
      "Episode: 541 Total reward: 9.0 Training loss: 12.2434 Explore P: 0.0252\n",
      "Episode: 542 Total reward: 9.0 Training loss: 0.7670 Explore P: 0.0251\n",
      "Episode: 543 Total reward: 9.0 Training loss: 2.4109 Explore P: 0.0249\n",
      "Episode: 544 Total reward: 9.0 Training loss: 9.1954 Explore P: 0.0248\n",
      "Episode: 545 Total reward: 10.0 Training loss: 3.0636 Explore P: 0.0247\n",
      "Episode: 546 Total reward: 7.0 Training loss: 2.8623 Explore P: 0.0246\n",
      "Episode: 547 Total reward: 8.0 Training loss: 3.9181 Explore P: 0.0245\n",
      "Episode: 548 Total reward: 8.0 Training loss: 0.8424 Explore P: 0.0244\n",
      "Episode: 549 Total reward: 11.0 Training loss: 6.9242 Explore P: 0.0243\n",
      "Episode: 550 Total reward: 8.0 Training loss: 7.4345 Explore P: 0.0242\n",
      "Episode: 551 Total reward: 12.0 Training loss: 8.4339 Explore P: 0.0241\n",
      "Episode: 552 Total reward: 9.0 Training loss: 24.2530 Explore P: 0.0240\n",
      "Episode: 553 Total reward: 10.0 Training loss: 7.6060 Explore P: 0.0239\n",
      "Episode: 554 Total reward: 8.0 Training loss: 1.5075 Explore P: 0.0238\n",
      "Episode: 555 Total reward: 9.0 Training loss: 7.1618 Explore P: 0.0237\n",
      "Episode: 556 Total reward: 9.0 Training loss: 1.2892 Explore P: 0.0236\n",
      "Episode: 557 Total reward: 8.0 Training loss: 6.2236 Explore P: 0.0235\n",
      "Episode: 558 Total reward: 11.0 Training loss: 0.9401 Explore P: 0.0234\n",
      "Episode: 559 Total reward: 35.0 Training loss: 8.3653 Explore P: 0.0230\n",
      "Episode: 560 Total reward: 36.0 Training loss: 0.8739 Explore P: 0.0226\n",
      "Episode: 561 Total reward: 12.0 Training loss: 2.9254 Explore P: 0.0225\n",
      "Episode: 562 Total reward: 10.0 Training loss: 0.6536 Explore P: 0.0223\n",
      "Episode: 563 Total reward: 14.0 Training loss: 13.3214 Explore P: 0.0222\n",
      "Episode: 564 Total reward: 13.0 Training loss: 7.7782 Explore P: 0.0221\n",
      "Episode: 565 Total reward: 11.0 Training loss: 0.9218 Explore P: 0.0219\n",
      "Episode: 566 Total reward: 8.0 Training loss: 9.2747 Explore P: 0.0219\n",
      "Episode: 567 Total reward: 13.0 Training loss: 5.2123 Explore P: 0.0217\n",
      "Episode: 568 Total reward: 8.0 Training loss: 15.4758 Explore P: 0.0216\n",
      "Episode: 569 Total reward: 15.0 Training loss: 7.2754 Explore P: 0.0215\n",
      "Episode: 570 Total reward: 9.0 Training loss: 3.7282 Explore P: 0.0214\n",
      "Episode: 571 Total reward: 11.0 Training loss: 0.7406 Explore P: 0.0213\n",
      "Episode: 572 Total reward: 12.0 Training loss: 5.2083 Explore P: 0.0212\n",
      "Episode: 573 Total reward: 11.0 Training loss: 10.9158 Explore P: 0.0211\n",
      "Episode: 574 Total reward: 12.0 Training loss: 0.8519 Explore P: 0.0209\n",
      "Episode: 575 Total reward: 10.0 Training loss: 10.0185 Explore P: 0.0208\n",
      "Episode: 576 Total reward: 13.0 Training loss: 0.9052 Explore P: 0.0207\n",
      "Episode: 577 Total reward: 11.0 Training loss: 3.9437 Explore P: 0.0206\n",
      "Episode: 578 Total reward: 47.0 Training loss: 7.9857 Explore P: 0.0201\n",
      "Episode: 579 Total reward: 13.0 Training loss: 1.2500 Explore P: 0.0200\n",
      "Episode: 580 Total reward: 32.0 Training loss: 4.4447 Explore P: 0.0197\n",
      "Episode: 581 Total reward: 43.0 Training loss: 6.1432 Explore P: 0.0193\n",
      "Episode: 582 Total reward: 22.0 Training loss: 4.9570 Explore P: 0.0191\n",
      "Episode: 583 Total reward: 19.0 Training loss: 1.5679 Explore P: 0.0189\n",
      "Episode: 584 Total reward: 13.0 Training loss: 4.6895 Explore P: 0.0188\n",
      "Episode: 585 Total reward: 13.0 Training loss: 1.1950 Explore P: 0.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 586 Total reward: 14.0 Training loss: 17.1781 Explore P: 0.0186\n",
      "Episode: 587 Total reward: 15.0 Training loss: 1.2962 Explore P: 0.0185\n",
      "Episode: 588 Total reward: 16.0 Training loss: 17.5360 Explore P: 0.0183\n",
      "Episode: 589 Total reward: 13.0 Training loss: 10.8348 Explore P: 0.0182\n",
      "Episode: 590 Total reward: 16.0 Training loss: 1.1357 Explore P: 0.0181\n",
      "Episode: 591 Total reward: 14.0 Training loss: 6.8345 Explore P: 0.0179\n",
      "Episode: 592 Total reward: 10.0 Training loss: 9.3290 Explore P: 0.0179\n",
      "Episode: 593 Total reward: 16.0 Training loss: 3.7276 Explore P: 0.0177\n",
      "Episode: 594 Total reward: 12.0 Training loss: 18.2558 Explore P: 0.0176\n",
      "Episode: 595 Total reward: 14.0 Training loss: 0.5257 Explore P: 0.0175\n",
      "Episode: 596 Total reward: 10.0 Training loss: 1.5064 Explore P: 0.0174\n",
      "Episode: 597 Total reward: 9.0 Training loss: 5.2314 Explore P: 0.0174\n",
      "Episode: 598 Total reward: 8.0 Training loss: 18.6117 Explore P: 0.0173\n",
      "Episode: 599 Total reward: 10.0 Training loss: 1.3234 Explore P: 0.0172\n",
      "Episode: 600 Total reward: 9.0 Training loss: 18.7688 Explore P: 0.0171\n",
      "Episode: 601 Total reward: 8.0 Training loss: 16.6536 Explore P: 0.0171\n",
      "Episode: 602 Total reward: 11.0 Training loss: 2.7883 Explore P: 0.0170\n",
      "Episode: 603 Total reward: 11.0 Training loss: 2.3987 Explore P: 0.0169\n",
      "Episode: 604 Total reward: 10.0 Training loss: 2.9377 Explore P: 0.0168\n",
      "Episode: 605 Total reward: 10.0 Training loss: 6.2600 Explore P: 0.0167\n",
      "Episode: 606 Total reward: 12.0 Training loss: 11.5818 Explore P: 0.0166\n",
      "Episode: 607 Total reward: 9.0 Training loss: 11.0371 Explore P: 0.0166\n",
      "Episode: 608 Total reward: 11.0 Training loss: 2.2253 Explore P: 0.0165\n",
      "Episode: 609 Total reward: 11.0 Training loss: 13.7994 Explore P: 0.0164\n",
      "Episode: 610 Total reward: 10.0 Training loss: 6.5725 Explore P: 0.0163\n",
      "Episode: 611 Total reward: 10.0 Training loss: 1.2953 Explore P: 0.0163\n",
      "Episode: 612 Total reward: 9.0 Training loss: 11.5169 Explore P: 0.0162\n",
      "Episode: 613 Total reward: 11.0 Training loss: 12.6937 Explore P: 0.0161\n",
      "Episode: 614 Total reward: 9.0 Training loss: 0.8069 Explore P: 0.0160\n",
      "Episode: 615 Total reward: 11.0 Training loss: 23.7618 Explore P: 0.0160\n",
      "Episode: 616 Total reward: 13.0 Training loss: 6.0271 Explore P: 0.0159\n",
      "Episode: 617 Total reward: 10.0 Training loss: 4.6888 Explore P: 0.0158\n",
      "Episode: 618 Total reward: 14.0 Training loss: 14.4807 Explore P: 0.0157\n",
      "Episode: 619 Total reward: 11.0 Training loss: 3.6497 Explore P: 0.0156\n",
      "Episode: 620 Total reward: 14.0 Training loss: 6.3401 Explore P: 0.0155\n",
      "Episode: 621 Total reward: 11.0 Training loss: 3.4044 Explore P: 0.0154\n",
      "Episode: 622 Total reward: 20.0 Training loss: 0.7944 Explore P: 0.0153\n",
      "Episode: 623 Total reward: 22.0 Training loss: 16.6334 Explore P: 0.0151\n",
      "Episode: 624 Total reward: 37.0 Training loss: 9.2785 Explore P: 0.0149\n",
      "Episode: 625 Total reward: 27.0 Training loss: 8.2558 Explore P: 0.0147\n",
      "Episode: 626 Total reward: 49.0 Training loss: 11.1627 Explore P: 0.0143\n",
      "Episode: 627 Total reward: 39.0 Training loss: 7.5950 Explore P: 0.0141\n",
      "Episode: 628 Total reward: 48.0 Training loss: 1.1248 Explore P: 0.0138\n",
      "Episode: 629 Total reward: 34.0 Training loss: 5.7080 Explore P: 0.0136\n",
      "Episode: 630 Total reward: 52.0 Training loss: 1.0143 Explore P: 0.0132\n",
      "Episode: 631 Total reward: 51.0 Training loss: 10.7487 Explore P: 0.0129\n",
      "Episode: 632 Total reward: 25.0 Training loss: 10.9302 Explore P: 0.0128\n",
      "Episode: 633 Total reward: 25.0 Training loss: 9.8352 Explore P: 0.0126\n",
      "Episode: 634 Total reward: 19.0 Training loss: 16.9972 Explore P: 0.0125\n",
      "Episode: 635 Total reward: 23.0 Training loss: 4.5794 Explore P: 0.0124\n",
      "Episode: 636 Total reward: 49.0 Training loss: 4.8254 Explore P: 0.0121\n",
      "Episode: 637 Total reward: 67.0 Training loss: 5.8812 Explore P: 0.0117\n",
      "Episode: 638 Total reward: 38.0 Training loss: 6.6058 Explore P: 0.0115\n",
      "Episode: 639 Total reward: 58.0 Training loss: 0.7805 Explore P: 0.0112\n",
      "Episode: 640 Total reward: 62.0 Training loss: 17.9284 Explore P: 0.0109\n",
      "Episode: 641 Total reward: 65.0 Training loss: 0.9496 Explore P: 0.0106\n",
      "Episode: 642 Total reward: 48.0 Training loss: 0.8844 Explore P: 0.0104\n",
      "Episode: 643 Total reward: 73.0 Training loss: 0.9739 Explore P: 0.0100\n",
      "Episode: 644 Total reward: 72.0 Training loss: 16.4216 Explore P: 0.0097\n",
      "Episode: 645 Total reward: 53.0 Training loss: 0.9725 Explore P: 0.0095\n",
      "Episode: 646 Total reward: 42.0 Training loss: 15.8967 Explore P: 0.0093\n",
      "Episode: 647 Total reward: 35.0 Training loss: 0.9442 Explore P: 0.0092\n",
      "Episode: 648 Total reward: 27.0 Training loss: 0.3544 Explore P: 0.0091\n",
      "Episode: 649 Total reward: 25.0 Training loss: 35.7893 Explore P: 0.0090\n",
      "Episode: 650 Total reward: 25.0 Training loss: 0.9084 Explore P: 0.0089\n",
      "Episode: 651 Total reward: 21.0 Training loss: 17.7180 Explore P: 0.0088\n",
      "Episode: 652 Total reward: 20.0 Training loss: 0.7646 Explore P: 0.0087\n",
      "Episode: 653 Total reward: 18.0 Training loss: 1.2608 Explore P: 0.0086\n",
      "Episode: 654 Total reward: 13.0 Training loss: 1.2199 Explore P: 0.0086\n",
      "Episode: 655 Total reward: 14.0 Training loss: 1.5830 Explore P: 0.0085\n",
      "Episode: 656 Total reward: 12.0 Training loss: 27.0086 Explore P: 0.0085\n",
      "Episode: 657 Total reward: 11.0 Training loss: 22.7774 Explore P: 0.0085\n",
      "Episode: 658 Total reward: 11.0 Training loss: 26.4906 Explore P: 0.0084\n",
      "Episode: 659 Total reward: 12.0 Training loss: 21.3590 Explore P: 0.0084\n",
      "Episode: 660 Total reward: 11.0 Training loss: 1.7407 Explore P: 0.0083\n",
      "Episode: 661 Total reward: 9.0 Training loss: 1.3640 Explore P: 0.0083\n",
      "Episode: 662 Total reward: 13.0 Training loss: 24.5704 Explore P: 0.0082\n",
      "Episode: 663 Total reward: 13.0 Training loss: 1.1340 Explore P: 0.0082\n",
      "Episode: 664 Total reward: 14.0 Training loss: 22.9598 Explore P: 0.0082\n",
      "Episode: 665 Total reward: 13.0 Training loss: 1.8403 Explore P: 0.0081\n",
      "Episode: 666 Total reward: 16.0 Training loss: 1.4616 Explore P: 0.0080\n",
      "Episode: 667 Total reward: 17.0 Training loss: 1.1867 Explore P: 0.0080\n",
      "Episode: 668 Total reward: 17.0 Training loss: 23.3366 Explore P: 0.0079\n",
      "Episode: 669 Total reward: 24.0 Training loss: 1.3992 Explore P: 0.0078\n",
      "Episode: 670 Total reward: 32.0 Training loss: 21.8146 Explore P: 0.0077\n",
      "Episode: 671 Total reward: 28.0 Training loss: 19.7097 Explore P: 0.0076\n",
      "Episode: 672 Total reward: 75.0 Training loss: 1.0130 Explore P: 0.0074\n",
      "Episode: 673 Total reward: 67.0 Training loss: 33.5283 Explore P: 0.0072\n",
      "Episode: 674 Total reward: 24.0 Training loss: 19.2544 Explore P: 0.0071\n",
      "Episode: 675 Total reward: 15.0 Training loss: 0.9249 Explore P: 0.0071\n",
      "Episode: 676 Total reward: 14.0 Training loss: 14.8526 Explore P: 0.0070\n",
      "Episode: 677 Total reward: 11.0 Training loss: 17.4108 Explore P: 0.0070\n",
      "Episode: 678 Total reward: 11.0 Training loss: 15.9869 Explore P: 0.0070\n",
      "Episode: 679 Total reward: 8.0 Training loss: 0.9934 Explore P: 0.0069\n",
      "Episode: 680 Total reward: 9.0 Training loss: 1.5217 Explore P: 0.0069\n",
      "Episode: 681 Total reward: 8.0 Training loss: 1.3577 Explore P: 0.0069\n",
      "Episode: 682 Total reward: 14.0 Training loss: 36.8914 Explore P: 0.0068\n",
      "Episode: 683 Total reward: 10.0 Training loss: 76.6664 Explore P: 0.0068\n",
      "Episode: 684 Total reward: 11.0 Training loss: 42.2488 Explore P: 0.0068\n",
      "Episode: 685 Total reward: 11.0 Training loss: 1.2866 Explore P: 0.0068\n",
      "Episode: 686 Total reward: 12.0 Training loss: 1.0430 Explore P: 0.0067\n",
      "Episode: 687 Total reward: 116.0 Training loss: 31.9588 Explore P: 0.0064\n",
      "Episode: 688 Total reward: 64.0 Training loss: 14.7222 Explore P: 0.0062\n",
      "Episode: 689 Total reward: 129.0 Training loss: 1.0960 Explore P: 0.0059\n",
      "Episode: 690 Total reward: 91.0 Training loss: 36.7829 Explore P: 0.0057\n",
      "Episode: 691 Total reward: 46.0 Training loss: 40.0531 Explore P: 0.0056\n",
      "Episode: 692 Total reward: 46.0 Training loss: 1.2311 Explore P: 0.0055\n",
      "Episode: 693 Total reward: 34.0 Training loss: 1.8833 Explore P: 0.0054\n",
      "Episode: 694 Total reward: 25.0 Training loss: 1.0229 Explore P: 0.0053\n",
      "Episode: 695 Total reward: 47.0 Training loss: 1.5861 Explore P: 0.0052\n",
      "Episode: 696 Total reward: 56.0 Training loss: 0.8436 Explore P: 0.0051\n",
      "Episode: 697 Total reward: 45.0 Training loss: 1.6688 Explore P: 0.0050\n",
      "Episode: 698 Total reward: 31.0 Training loss: 0.4239 Explore P: 0.0050\n",
      "Episode: 699 Total reward: 25.0 Training loss: 1.8827 Explore P: 0.0049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 700 Total reward: 22.0 Training loss: 1.9052 Explore P: 0.0049\n",
      "Episode: 701 Total reward: 30.0 Training loss: 59.8830 Explore P: 0.0048\n",
      "Episode: 702 Total reward: 21.0 Training loss: 30.6745 Explore P: 0.0048\n",
      "Episode: 703 Total reward: 23.0 Training loss: 52.9744 Explore P: 0.0047\n",
      "Episode: 704 Total reward: 26.0 Training loss: 30.6665 Explore P: 0.0047\n",
      "Episode: 705 Total reward: 21.0 Training loss: 1.0410 Explore P: 0.0047\n",
      "Episode: 706 Total reward: 18.0 Training loss: 1.1623 Explore P: 0.0046\n",
      "Episode: 707 Total reward: 14.0 Training loss: 1.7231 Explore P: 0.0046\n",
      "Episode: 708 Total reward: 21.0 Training loss: 0.7741 Explore P: 0.0046\n",
      "Episode: 709 Total reward: 27.0 Training loss: 24.7979 Explore P: 0.0045\n",
      "Episode: 710 Total reward: 30.0 Training loss: 0.6657 Explore P: 0.0045\n",
      "Episode: 711 Total reward: 23.0 Training loss: 26.7090 Explore P: 0.0044\n",
      "Episode: 712 Total reward: 22.0 Training loss: 21.9735 Explore P: 0.0044\n",
      "Episode: 713 Total reward: 28.0 Training loss: 1.0560 Explore P: 0.0043\n",
      "Episode: 714 Total reward: 30.0 Training loss: 0.8774 Explore P: 0.0043\n",
      "Episode: 715 Total reward: 38.0 Training loss: 23.8033 Explore P: 0.0042\n",
      "Episode: 716 Total reward: 38.0 Training loss: 24.6032 Explore P: 0.0042\n",
      "Episode: 717 Total reward: 42.0 Training loss: 0.9787 Explore P: 0.0041\n",
      "Episode: 718 Total reward: 50.0 Training loss: 24.3445 Explore P: 0.0040\n",
      "Episode: 719 Total reward: 72.0 Training loss: 22.2341 Explore P: 0.0039\n",
      "Episode: 720 Total reward: 63.0 Training loss: 0.3189 Explore P: 0.0038\n",
      "Episode: 721 Total reward: 46.0 Training loss: 0.4455 Explore P: 0.0038\n",
      "Episode: 722 Total reward: 57.0 Training loss: 0.4071 Explore P: 0.0037\n",
      "Episode: 723 Total reward: 66.0 Training loss: 17.2352 Explore P: 0.0036\n",
      "Episode: 724 Total reward: 59.0 Training loss: 0.3729 Explore P: 0.0035\n",
      "Episode: 725 Total reward: 93.0 Training loss: 0.4193 Explore P: 0.0034\n",
      "Episode: 726 Total reward: 77.0 Training loss: 0.4985 Explore P: 0.0033\n",
      "Episode: 727 Total reward: 84.0 Training loss: 18.5209 Explore P: 0.0032\n",
      "Episode: 728 Total reward: 83.0 Training loss: 0.2547 Explore P: 0.0031\n",
      "Episode: 729 Total reward: 77.0 Training loss: 0.3285 Explore P: 0.0030\n",
      "Episode: 730 Total reward: 50.0 Training loss: 16.7956 Explore P: 0.0030\n",
      "Episode: 731 Total reward: 50.0 Training loss: 0.2983 Explore P: 0.0029\n",
      "Episode: 732 Total reward: 33.0 Training loss: 0.2328 Explore P: 0.0029\n",
      "Episode: 733 Total reward: 30.0 Training loss: 0.4447 Explore P: 0.0029\n",
      "Episode: 734 Total reward: 35.0 Training loss: 0.5885 Explore P: 0.0029\n",
      "Episode: 735 Total reward: 38.0 Training loss: 22.5646 Explore P: 0.0028\n",
      "Episode: 736 Total reward: 28.0 Training loss: 0.4148 Explore P: 0.0028\n",
      "Episode: 737 Total reward: 38.0 Training loss: 0.5494 Explore P: 0.0028\n",
      "Episode: 738 Total reward: 25.0 Training loss: 0.6452 Explore P: 0.0027\n",
      "Episode: 739 Total reward: 25.0 Training loss: 0.7061 Explore P: 0.0027\n",
      "Episode: 740 Total reward: 22.0 Training loss: 0.7214 Explore P: 0.0027\n",
      "Episode: 741 Total reward: 27.0 Training loss: 0.3765 Explore P: 0.0027\n",
      "Episode: 742 Total reward: 20.0 Training loss: 0.4119 Explore P: 0.0027\n",
      "Episode: 743 Total reward: 16.0 Training loss: 0.9340 Explore P: 0.0026\n",
      "Episode: 744 Total reward: 19.0 Training loss: 0.8743 Explore P: 0.0026\n",
      "Episode: 745 Total reward: 20.0 Training loss: 0.8780 Explore P: 0.0026\n",
      "Episode: 746 Total reward: 18.0 Training loss: 19.3184 Explore P: 0.0026\n",
      "Episode: 747 Total reward: 13.0 Training loss: 0.5114 Explore P: 0.0026\n",
      "Episode: 748 Total reward: 14.0 Training loss: 0.9257 Explore P: 0.0026\n",
      "Episode: 749 Total reward: 15.0 Training loss: 0.7217 Explore P: 0.0026\n",
      "Episode: 750 Total reward: 12.0 Training loss: 25.1008 Explore P: 0.0026\n",
      "Episode: 751 Total reward: 12.0 Training loss: 0.9677 Explore P: 0.0025\n",
      "Episode: 752 Total reward: 11.0 Training loss: 1.3954 Explore P: 0.0025\n",
      "Episode: 753 Total reward: 12.0 Training loss: 1.5505 Explore P: 0.0025\n",
      "Episode: 754 Total reward: 13.0 Training loss: 0.7676 Explore P: 0.0025\n",
      "Episode: 755 Total reward: 13.0 Training loss: 0.8284 Explore P: 0.0025\n",
      "Episode: 756 Total reward: 11.0 Training loss: 1.2282 Explore P: 0.0025\n",
      "Episode: 757 Total reward: 10.0 Training loss: 1.1583 Explore P: 0.0025\n",
      "Episode: 758 Total reward: 13.0 Training loss: 23.2847 Explore P: 0.0025\n",
      "Episode: 759 Total reward: 14.0 Training loss: 22.5065 Explore P: 0.0025\n",
      "Episode: 760 Total reward: 19.0 Training loss: 0.8506 Explore P: 0.0025\n",
      "Episode: 761 Total reward: 36.0 Training loss: 52.4496 Explore P: 0.0024\n",
      "Episode: 762 Total reward: 39.0 Training loss: 16.8115 Explore P: 0.0024\n",
      "Episode: 763 Total reward: 132.0 Training loss: 0.5774 Explore P: 0.0023\n",
      "Episode: 764 Total reward: 131.0 Training loss: 1.1065 Explore P: 0.0022\n",
      "Episode: 765 Total reward: 45.0 Training loss: 0.6393 Explore P: 0.0022\n",
      "Episode: 766 Total reward: 35.0 Training loss: 17.4286 Explore P: 0.0022\n",
      "Episode: 767 Total reward: 38.0 Training loss: 1.0570 Explore P: 0.0022\n",
      "Episode: 768 Total reward: 45.0 Training loss: 1.4864 Explore P: 0.0021\n",
      "Episode: 769 Total reward: 104.0 Training loss: 0.9204 Explore P: 0.0021\n",
      "Episode: 770 Total reward: 73.0 Training loss: 0.5504 Explore P: 0.0020\n",
      "Episode: 771 Total reward: 76.0 Training loss: 1.5800 Explore P: 0.0020\n",
      "Episode: 772 Total reward: 60.0 Training loss: 1.4404 Explore P: 0.0020\n",
      "Episode: 773 Total reward: 75.0 Training loss: 16.3222 Explore P: 0.0019\n",
      "Episode: 774 Total reward: 101.0 Training loss: 1.5939 Explore P: 0.0019\n",
      "Episode: 775 Total reward: 56.0 Training loss: 1.4995 Explore P: 0.0019\n",
      "Episode: 776 Total reward: 142.0 Training loss: 0.9367 Explore P: 0.0018\n",
      "Episode: 777 Total reward: 198.0 Training loss: 1.4812 Explore P: 0.0017\n",
      "Episode: 778 Total reward: 126.0 Training loss: 1.5323 Explore P: 0.0017\n",
      "Episode: 779 Total reward: 116.0 Training loss: 1.7303 Explore P: 0.0016\n",
      "Episode: 780 Total reward: 121.0 Training loss: 1.5620 Explore P: 0.0016\n",
      "Episode: 781 Total reward: 117.0 Training loss: 0.9649 Explore P: 0.0016\n",
      "Episode: 782 Total reward: 70.0 Training loss: 2.0015 Explore P: 0.0016\n",
      "Episode: 783 Total reward: 55.0 Training loss: 37.7121 Explore P: 0.0015\n",
      "Episode: 784 Total reward: 55.0 Training loss: 1.0487 Explore P: 0.0015\n",
      "Episode: 785 Total reward: 49.0 Training loss: 2.2348 Explore P: 0.0015\n",
      "Episode: 786 Total reward: 103.0 Training loss: 51.2314 Explore P: 0.0015\n",
      "Episode: 787 Total reward: 93.0 Training loss: 1.1478 Explore P: 0.0015\n",
      "Episode: 788 Total reward: 78.0 Training loss: 0.7342 Explore P: 0.0014\n",
      "Episode: 789 Total reward: 93.0 Training loss: 72.5940 Explore P: 0.0014\n",
      "Episode: 790 Total reward: 72.0 Training loss: 1.0162 Explore P: 0.0014\n",
      "Episode: 791 Total reward: 58.0 Training loss: 48.1385 Explore P: 0.0014\n",
      "Episode: 792 Total reward: 73.0 Training loss: 0.6222 Explore P: 0.0014\n",
      "Episode: 793 Total reward: 93.0 Training loss: 1.3515 Explore P: 0.0014\n",
      "Episode: 794 Total reward: 75.0 Training loss: 0.4413 Explore P: 0.0014\n",
      "Episode: 795 Total reward: 93.0 Training loss: 0.2919 Explore P: 0.0013\n",
      "Episode: 796 Total reward: 99.0 Training loss: 0.2930 Explore P: 0.0013\n",
      "Episode: 797 Total reward: 92.0 Training loss: 0.7297 Explore P: 0.0013\n",
      "Episode: 798 Total reward: 94.0 Training loss: 0.2600 Explore P: 0.0013\n",
      "Episode: 799 Total reward: 79.0 Training loss: 0.2602 Explore P: 0.0013\n",
      "Episode: 800 Total reward: 88.0 Training loss: 0.2515 Explore P: 0.0013\n",
      "Episode: 801 Total reward: 79.0 Training loss: 0.1818 Explore P: 0.0013\n",
      "Episode: 802 Total reward: 75.0 Training loss: 0.4022 Explore P: 0.0012\n",
      "Episode: 803 Total reward: 74.0 Training loss: 0.3750 Explore P: 0.0012\n",
      "Episode: 804 Total reward: 88.0 Training loss: 39.7795 Explore P: 0.0012\n",
      "Episode: 805 Total reward: 79.0 Training loss: 0.2509 Explore P: 0.0012\n",
      "Episode: 806 Total reward: 75.0 Training loss: 0.5378 Explore P: 0.0012\n",
      "Episode: 807 Total reward: 84.0 Training loss: 29.4774 Explore P: 0.0012\n",
      "Episode: 808 Total reward: 72.0 Training loss: 0.4540 Explore P: 0.0012\n",
      "Episode: 809 Total reward: 81.0 Training loss: 0.2189 Explore P: 0.0012\n",
      "Episode: 810 Total reward: 99.0 Training loss: 23.4270 Explore P: 0.0012\n",
      "Episode: 811 Total reward: 96.0 Training loss: 0.2423 Explore P: 0.0012\n",
      "Episode: 812 Total reward: 96.0 Training loss: 0.1616 Explore P: 0.0012\n",
      "Episode: 813 Total reward: 89.0 Training loss: 0.3207 Explore P: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 814 Total reward: 103.0 Training loss: 0.3333 Explore P: 0.0011\n",
      "Episode: 815 Total reward: 104.0 Training loss: 0.2374 Explore P: 0.0011\n",
      "Episode: 816 Total reward: 98.0 Training loss: 12.6380 Explore P: 0.0011\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-df12b25e6b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mQAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mQAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetQs_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mQAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions_\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             })\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epsilon_max = 1.0\n",
    "epsilon_min = 0.001\n",
    "epsilon_decay = 0.0005\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "rewards_list = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    \n",
    "    for ep in range(1,1000):\n",
    "        total_reward = 0\n",
    "        t = 0\n",
    "        \n",
    "        while True:\n",
    "            step+=1\n",
    "            \n",
    "            epsilon = epsilon_min + (epsilon_max-epsilon_min)*np.exp(-epsilon_decay*step)\n",
    "            \n",
    "            if epsilon > np.random.rand():\n",
    "                action = env.action_space.sample()\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                feed = {QAgent.inputs_: state.reshape((1, *state.shape))}\n",
    "                Q_s = sess.run(QAgent.output, feed_dict = feed)\n",
    "                action = np.argmax(Q_s)\n",
    "                \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            total_reward +=reward\n",
    "            \n",
    "            if done:\n",
    "                \n",
    "                next_state = np.zeros(state.shape)\n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(epsilon))\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                env.reset()\n",
    "                \n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "                break\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "\n",
    "                \n",
    "            batch = memory.sample(batch_size=20)\n",
    "            \n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            target_Qs = sess.run(QAgent.output, feed_dict={QAgent.inputs_ : next_states})\n",
    "            \n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0,0)\n",
    "            \n",
    "            targets = reward + 0.99*np.max(target_Qs, axis=1)\n",
    "            \n",
    "            loss, _ = sess.run([QAgent.loss, QAgent.opt], feed_dict={\n",
    "                QAgent.inputs_ : states,\n",
    "                QAgent.targetQs_ : targets,\n",
    "                QAgent.actions_ : actions\n",
    "            })\n",
    "            \n",
    "    saver.save(sess, \"checkpoints/cartpole.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1a75a6fb00>,\n",
       " <matplotlib.lines.Line2D at 0x7f1a759a1d68>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
